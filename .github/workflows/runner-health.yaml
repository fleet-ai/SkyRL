name: Runner Health Check

on:
  schedule:
    # Run every 15 minutes
    - cron: '*/15 * * * *'
  workflow_dispatch:

permissions:
  contents: read

jobs:
  check-runners:
    name: Check Runner Status
    runs-on: ubuntu-latest
    steps:
      - name: Restore previous state
        id: cache
        uses: actions/cache/restore@v4
        with:
          path: /tmp/runner-health-state
          key: runner-health-state-${{ github.repository }}
          restore-keys: runner-health-state-

      - name: Load previous state
        id: prev
        run: |
          if [ -f /tmp/runner-health-state/state.json ]; then
            cat /tmp/runner-health-state/state.json
            PREV_COUNT=$(jq -r '.unhealthy_count // 0' /tmp/runner-health-state/state.json)
            echo "unhealthy_count=$PREV_COUNT" >> $GITHUB_OUTPUT
            echo "Previous unhealthy count: $PREV_COUNT"
          elif [ -f /tmp/runner-health-state/last_unhealthy_count ]; then
            # Migration from old format
            PREV=$(cat /tmp/runner-health-state/last_unhealthy_count)
            echo "unhealthy_count=$PREV" >> $GITHUB_OUTPUT
            echo "Migrated from old state format, unhealthy count: $PREV"
          else
            echo "unhealthy_count=0" >> $GITHUB_OUTPUT
            echo "No previous state found"
          fi

      - name: Check EC2 instance health
        id: ec2
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1
        run: |
          set +e  # Don't exit on errors

          # Runner instance IDs and names (from docs/gha-runner-setup.md)
          RUNNERS="i-04a15158610df980f:fleet-runner-1 i-0f80c703294413a4c:fleet-runner-2 i-09321b67952c1a208:fleet-runner-3 i-0f2ccaa840ef29450:fleet-runner-4 i-05ecd98e74949dc87:fleet-runner-5"

          # Function to check instance with retries
          check_instance() {
            local id=$1
            local retries=3
            local delay=5
            for i in $(seq 1 $retries); do
              RESULT=$(timeout 10 aws ec2 describe-instance-status --instance-ids "$id" --include-all-instances --query 'InstanceStatuses[0].[InstanceState.Name,InstanceStatus.Status]' --output text 2>/dev/null)
              if [ -n "$RESULT" ] && [ "$RESULT" != "None" ]; then
                echo "$RESULT"
                return 0
              fi
              [ $i -lt $retries ] && sleep $delay
            done
            echo "unknown unknown"
            return 1
          }

          echo "## EC2 Runner Health" >> $GITHUB_STEP_SUMMARY
          echo "| Runner | Instance | State | Health |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|----------|-------|--------|" >> $GITHUB_STEP_SUMMARY

          UNHEALTHY=""
          UNHEALTHY_NAMES=""
          TOTAL=0
          HEALTHY=0
          UNHEALTHY_DETAILS="[]"

          for entry in $RUNNERS; do
            id=$(echo $entry | cut -d: -f1)
            NAME=$(echo $entry | cut -d: -f2)
            TOTAL=$((TOTAL + 1))

            # Get instance state and status with retries
            RESULT=$(check_instance "$id")
            STATE=$(echo $RESULT | awk '{print $1}')
            HEALTH=$(echo $RESULT | awk '{print $2}')

            # Check if healthy (running + ok)
            if [ "$STATE" = "running" ] && [ "$HEALTH" = "ok" ]; then
              HEALTHY=$((HEALTHY + 1))
              echo "| $NAME | $id | âœ… $STATE | $HEALTH |" >> $GITHUB_STEP_SUMMARY
            else
              UNHEALTHY="$UNHEALTHY $id"
              UNHEALTHY_NAMES="$UNHEALTHY_NAMES $NAME"
              UNHEALTHY_DETAILS=$(echo "$UNHEALTHY_DETAILS" | jq --arg id "$id" --arg name "$NAME" --arg state "$STATE" --arg health "$HEALTH" '. + [{"id": $id, "name": $name, "state": $state, "health": $health}]')
              echo "| $NAME | $id | âŒ $STATE | $HEALTH |" >> $GITHUB_STEP_SUMMARY
            fi
          done

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Summary:** $HEALTHY/$TOTAL healthy" >> $GITHUB_STEP_SUMMARY

          # If unhealthy, wait 30s and recheck to avoid transient false positives
          UNHEALTHY_COUNT=$((TOTAL - HEALTHY))
          if [ "$UNHEALTHY_COUNT" -gt 0 ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Confirmation check in 30s...**" >> $GITHUB_STEP_SUMMARY
            sleep 30

            # Recheck only the unhealthy instances
            CONFIRMED_UNHEALTHY=""
            CONFIRMED_NAMES=""
            CONFIRMED_DETAILS="[]"
            for id in $UNHEALTHY; do
              RESULT=$(check_instance "$id")
              STATE=$(echo $RESULT | awk '{print $1}')
              HEALTH=$(echo $RESULT | awk '{print $2}')
              if [ "$STATE" != "running" ] || [ "$HEALTH" != "ok" ]; then
                for entry in $RUNNERS; do
                  eid=$(echo $entry | cut -d: -f1)
                  ename=$(echo $entry | cut -d: -f2)
                  if [ "$eid" = "$id" ]; then
                    CONFIRMED_UNHEALTHY="$CONFIRMED_UNHEALTHY $id"
                    CONFIRMED_NAMES="$CONFIRMED_NAMES $ename"
                    CONFIRMED_DETAILS=$(echo "$CONFIRMED_DETAILS" | jq --arg id "$id" --arg name "$ename" --arg state "$STATE" --arg health "$HEALTH" '. + [{"id": $id, "name": $name, "state": $state, "health": $health}]')
                    break
                  fi
                done
              fi
            done

            UNHEALTHY=$(echo $CONFIRMED_UNHEALTHY | xargs)
            UNHEALTHY_NAMES=$(echo $CONFIRMED_NAMES | xargs)
            UNHEALTHY_COUNT=$(echo $UNHEALTHY | wc -w | tr -d ' ')
            UNHEALTHY_DETAILS="$CONFIRMED_DETAILS"
            HEALTHY=$((TOTAL - UNHEALTHY_COUNT))

            if [ "$UNHEALTHY_COUNT" -eq 0 ]; then
              echo "âœ… **Confirmation: All runners recovered (transient issue)**" >> $GITHUB_STEP_SUMMARY
            else
              echo "âŒ **Confirmed unhealthy:** $UNHEALTHY_NAMES" >> $GITHUB_STEP_SUMMARY
            fi
          fi

          # Export for subsequent steps
          echo "total=$TOTAL" >> $GITHUB_OUTPUT
          echo "healthy=$HEALTHY" >> $GITHUB_OUTPUT
          echo "unhealthy_count=$UNHEALTHY_COUNT" >> $GITHUB_OUTPUT
          echo "unhealthy_ids=$UNHEALTHY" >> $GITHUB_OUTPUT
          echo "unhealthy_names=$UNHEALTHY_NAMES" >> $GITHUB_OUTPUT
          # Write details to file (too large for output variable)
          echo "$UNHEALTHY_DETAILS" > /tmp/unhealthy_details.json

      - name: Auto-recover unhealthy instances
        id: recover
        if: steps.ec2.outputs.unhealthy_count != '0'
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set +e
          MAX_ATTEMPTS=2

          # Load per-instance recovery attempt counts from previous state
          if [ -f /tmp/runner-health-state/state.json ]; then
            PREV_ATTEMPTS=$(jq -r '.recovery_attempts // {}' /tmp/runner-health-state/state.json)
          else
            PREV_ATTEMPTS="{}"
          fi

          # Get list of runners currently executing a job (busy runners)
          BUSY_RUNNERS=$(gh api repos/${{ github.repository }}/actions/runners --paginate --jq '.runners[] | select(.busy == true) | .name' 2>/dev/null || echo "")
          if [ -n "$BUSY_RUNNERS" ]; then
            echo "Busy runners (will not stop/start): $BUSY_RUNNERS"
          fi

          DETAILS=$(cat /tmp/unhealthy_details.json)
          COUNT=$(echo "$DETAILS" | jq 'length')

          RECOVERED_NAMES=""
          RECOVERED_COUNT=0
          FAILED_NAMES=""
          FAILED_COUNT=0
          SKIPPED_NAMES=""
          SKIPPED_COUNT=0
          # Track updated attempt counts (will be saved in state)
          UPDATED_ATTEMPTS="$PREV_ATTEMPTS"

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Auto-Recovery" >> $GITHUB_STEP_SUMMARY

          for i in $(seq 0 $((COUNT - 1))); do
            INSTANCE_ID=$(echo "$DETAILS" | jq -r ".[$i].id")
            INSTANCE_NAME=$(echo "$DETAILS" | jq -r ".[$i].name")
            INSTANCE_STATE=$(echo "$DETAILS" | jq -r ".[$i].state")
            INSTANCE_HEALTH=$(echo "$DETAILS" | jq -r ".[$i].health")

            # Get previous attempt count for this instance
            ATTEMPTS=$(echo "$PREV_ATTEMPTS" | jq -r --arg id "$INSTANCE_ID" '.[$id] // 0')

            echo "Processing $INSTANCE_NAME ($INSTANCE_ID): state=$INSTANCE_STATE health=$INSTANCE_HEALTH attempts=$ATTEMPTS"

            # Skip if runner is actively executing a job
            if echo "$BUSY_RUNNERS" | grep -qx "$INSTANCE_NAME"; then
              echo "â­ï¸ **$INSTANCE_NAME**: Skipped â€” runner is busy (executing a job)" >> $GITHUB_STEP_SUMMARY
              SKIPPED_NAMES="$SKIPPED_NAMES $INSTANCE_NAME"
              SKIPPED_COUNT=$((SKIPPED_COUNT + 1))
              continue
            fi

            # Skip if max attempts reached
            if [ "$ATTEMPTS" -ge "$MAX_ATTEMPTS" ]; then
              echo "â­ï¸ **$INSTANCE_NAME**: Skipped â€” $ATTEMPTS recovery attempts exhausted, needs manual intervention" >> $GITHUB_STEP_SUMMARY
              SKIPPED_NAMES="$SKIPPED_NAMES $INSTANCE_NAME"
              SKIPPED_COUNT=$((SKIPPED_COUNT + 1))
              continue
            fi

            # Skip terminated/shutting-down instances â€” can't recover these
            if [ "$INSTANCE_STATE" = "terminated" ] || [ "$INSTANCE_STATE" = "shutting-down" ]; then
              echo "â­ï¸ **$INSTANCE_NAME**: Skipped â€” instance is $INSTANCE_STATE" >> $GITHUB_STEP_SUMMARY
              SKIPPED_NAMES="$SKIPPED_NAMES $INSTANCE_NAME"
              SKIPPED_COUNT=$((SKIPPED_COUNT + 1))
              continue
            fi

            echo "ðŸ”„ **$INSTANCE_NAME**: Attempting recovery (attempt $((ATTEMPTS + 1))/$MAX_ATTEMPTS)..." >> $GITHUB_STEP_SUMMARY

            # Recovery strategy: stop/start (reboot doesn't fix impaired instances)
            if [ "$INSTANCE_STATE" = "stopped" ]; then
              echo "  Instance already stopped, starting..."
              aws ec2 start-instances --instance-ids "$INSTANCE_ID" > /dev/null 2>&1
            elif [ "$INSTANCE_STATE" = "running" ]; then
              echo "  Stopping instance..."
              aws ec2 stop-instances --instance-ids "$INSTANCE_ID" > /dev/null 2>&1
              echo "  Waiting for instance to stop..."
              aws ec2 wait instance-stopped --instance-ids "$INSTANCE_ID" 2>/dev/null
              echo "  Starting instance..."
              aws ec2 start-instances --instance-ids "$INSTANCE_ID" > /dev/null 2>&1
            elif [ "$INSTANCE_STATE" = "stopping" ]; then
              echo "  Instance is stopping, waiting..."
              aws ec2 wait instance-stopped --instance-ids "$INSTANCE_ID" 2>/dev/null
              echo "  Starting instance..."
              aws ec2 start-instances --instance-ids "$INSTANCE_ID" > /dev/null 2>&1
            else
              echo "  Unexpected state '$INSTANCE_STATE', attempting start..."
              aws ec2 start-instances --instance-ids "$INSTANCE_ID" > /dev/null 2>&1
            fi

            # Wait for instance to be running and pass status checks (up to 10 min)
            echo "  Waiting for instance to pass status checks..."
            if timeout 600 aws ec2 wait instance-status-ok --instance-ids "$INSTANCE_ID" 2>/dev/null; then
              echo "âœ… **$INSTANCE_NAME**: Recovered successfully" >> $GITHUB_STEP_SUMMARY
              RECOVERED_NAMES="$RECOVERED_NAMES $INSTANCE_NAME"
              RECOVERED_COUNT=$((RECOVERED_COUNT + 1))
              # Reset attempt counter on success
              UPDATED_ATTEMPTS=$(echo "$UPDATED_ATTEMPTS" | jq --arg id "$INSTANCE_ID" 'del(.[$id])')
            else
              echo "âŒ **$INSTANCE_NAME**: Recovery failed (instance did not pass status checks)" >> $GITHUB_STEP_SUMMARY
              FAILED_NAMES="$FAILED_NAMES $INSTANCE_NAME"
              FAILED_COUNT=$((FAILED_COUNT + 1))
              # Increment attempt counter
              UPDATED_ATTEMPTS=$(echo "$UPDATED_ATTEMPTS" | jq --arg id "$INSTANCE_ID" --argjson n $((ATTEMPTS + 1)) '.[$id] = $n')
            fi
          done

          RECOVERED_NAMES=$(echo $RECOVERED_NAMES | xargs)
          FAILED_NAMES=$(echo $FAILED_NAMES | xargs)
          SKIPPED_NAMES=$(echo $SKIPPED_NAMES | xargs)
          STILL_UNHEALTHY=$((FAILED_COUNT + SKIPPED_COUNT))

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Recovery summary:** $RECOVERED_COUNT recovered, $FAILED_COUNT failed, $SKIPPED_COUNT skipped" >> $GITHUB_STEP_SUMMARY

          echo "recovered_count=$RECOVERED_COUNT" >> $GITHUB_OUTPUT
          echo "recovered_names=$RECOVERED_NAMES" >> $GITHUB_OUTPUT
          echo "failed_count=$FAILED_COUNT" >> $GITHUB_OUTPUT
          echo "failed_names=$FAILED_NAMES" >> $GITHUB_OUTPUT
          echo "skipped_count=$SKIPPED_COUNT" >> $GITHUB_OUTPUT
          echo "skipped_names=$SKIPPED_NAMES" >> $GITHUB_OUTPUT
          echo "still_unhealthy=$STILL_UNHEALTHY" >> $GITHUB_OUTPUT

          # Save updated attempts for state step
          echo "$UPDATED_ATTEMPTS" > /tmp/updated_recovery_attempts.json

      - name: Check queued jobs
        id: queue
        continue-on-error: true
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          QUEUED=$(gh run list --repo ${{ github.repository }} --status queued --json databaseId --jq 'length' 2>/dev/null || echo "0")
          IN_PROGRESS=$(gh run list --repo ${{ github.repository }} --status in_progress --json databaseId --jq 'length' 2>/dev/null || echo "0")

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Jobs:** $QUEUED queued, $IN_PROGRESS in progress" >> $GITHUB_STEP_SUMMARY

          echo "queued=$QUEUED" >> $GITHUB_OUTPUT
          echo "in_progress=$IN_PROGRESS" >> $GITHUB_OUTPUT

      - name: Save current state
        if: always()
        run: |
          mkdir -p /tmp/runner-health-state

          # Load recovery attempts (from auto-recover step, or previous state)
          if [ -f /tmp/updated_recovery_attempts.json ]; then
            ATTEMPTS=$(cat /tmp/updated_recovery_attempts.json)
          elif [ -f /tmp/runner-health-state/state.json ]; then
            ATTEMPTS=$(jq -r '.recovery_attempts // {}' /tmp/runner-health-state/state.json)
          else
            ATTEMPTS="{}"
          fi

          # Determine final unhealthy count (after recovery)
          STILL_UNHEALTHY="${{ steps.recover.outputs.still_unhealthy }}"
          if [ -z "$STILL_UNHEALTHY" ]; then
            STILL_UNHEALTHY="${{ steps.ec2.outputs.unhealthy_count }}"
          fi

          jq -n --argjson attempts "$ATTEMPTS" --argjson count "${STILL_UNHEALTHY:-0}" '{unhealthy_count: $count, recovery_attempts: $attempts, updated_at: now | todate}' > /tmp/runner-health-state/state.json

          # Remove old format file if it exists
          rm -f /tmp/runner-health-state/last_unhealthy_count

          echo "Saved state:"
          cat /tmp/runner-health-state/state.json

      - name: Update cache
        if: always()
        uses: actions/cache/save@v4
        with:
          path: /tmp/runner-health-state
          key: runner-health-state-${{ github.repository }}-${{ github.run_id }}

      - name: Alert - auto-recovery succeeded
        if: steps.recover.outputs.recovered_count != '' && steps.recover.outputs.recovered_count != '0' && steps.recover.outputs.still_unhealthy == '0'
        uses: slackapi/slack-github-action@v2.0.0
        with:
          method: chat.postMessage
          token: ${{ secrets.SLACK_BOT_TOKEN }}
          payload: |
            {
              "channel": "#fleet-training-runs",
              "text": "ðŸ”§ Runners Auto-Recovered",
              "blocks": [
                {
                  "type": "header",
                  "text": { "type": "plain_text", "text": "ðŸ”§ Runners Auto-Recovered" }
                },
                {
                  "type": "section",
                  "fields": [
                    { "type": "mrkdwn", "text": "*Recovered:*\n${{ steps.recover.outputs.recovered_names }}" },
                    { "type": "mrkdwn", "text": "*Method:*\nEC2 stop/start" }
                  ]
                },
                {
                  "type": "context",
                  "elements": [
                    { "type": "mrkdwn", "text": "No action needed. | <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View Run>" }
                  ]
                }
              ]
            }

      - name: Alert - manual intervention needed
        if: steps.recover.outputs.still_unhealthy != '' && steps.recover.outputs.still_unhealthy != '0'
        uses: slackapi/slack-github-action@v2.0.0
        with:
          method: chat.postMessage
          token: ${{ secrets.SLACK_BOT_TOKEN }}
          payload: |
            {
              "channel": "#fleet-training-runs",
              "text": "ðŸš¨ Runner Recovery Failed â€” Manual Intervention Needed",
              "blocks": [
                {
                  "type": "header",
                  "text": { "type": "plain_text", "text": "ðŸš¨ Manual Intervention Needed" }
                },
                {
                  "type": "section",
                  "fields": [
                    { "type": "mrkdwn", "text": "*Still unhealthy:*\n${{ steps.recover.outputs.failed_names }} ${{ steps.recover.outputs.skipped_names }}" },
                    { "type": "mrkdwn", "text": "*Auto-recovered:*\n${{ steps.recover.outputs.recovered_names || 'none' }}" }
                  ]
                },
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "Auto-recovery via stop/start failed or max attempts reached.\nManual fix: `aws ec2 stop-instances --instance-ids <ID>` then `aws ec2 start-instances --instance-ids <ID>`\nOr launch a replacement runner per `docs/gha-runner-setup.md`."
                  }
                },
                {
                  "type": "context",
                  "elements": [
                    { "type": "mrkdwn", "text": "<https://github.com/${{ github.repository }}/settings/actions/runners|Manage Runners> | <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View Run>" }
                  ]
                }
              ]
            }

      - name: Alert - all runners healthy (recovered from previous issue)
        if: steps.ec2.outputs.unhealthy_count == '0' && steps.prev.outputs.unhealthy_count != '0'
        uses: slackapi/slack-github-action@v2.0.0
        with:
          method: chat.postMessage
          token: ${{ secrets.SLACK_BOT_TOKEN }}
          payload: |
            {
              "channel": "#fleet-training-runs",
              "text": "âœ… All Runners Healthy",
              "blocks": [
                {
                  "type": "header",
                  "text": { "type": "plain_text", "text": "âœ… All Runners Healthy" }
                },
                {
                  "type": "section",
                  "text": { "type": "mrkdwn", "text": "*Status:* ${{ steps.ec2.outputs.healthy }}/${{ steps.ec2.outputs.total }} runners online" }
                },
                {
                  "type": "context",
                  "elements": [
                    { "type": "mrkdwn", "text": "<${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View Run>" }
                  ]
                }
              ]
            }

      - name: Fail if runners still unhealthy after recovery
        if: steps.recover.outputs.still_unhealthy != '' && steps.recover.outputs.still_unhealthy != '0'
        run: |
          echo "::error::${{ steps.recover.outputs.still_unhealthy }} runner(s) still unhealthy after auto-recovery: ${{ steps.recover.outputs.failed_names }} ${{ steps.recover.outputs.skipped_names }}"
          exit 1
